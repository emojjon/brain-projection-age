{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde2df3f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d45e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ArgParse\n",
    "import Dates\n",
    "import NIfTI\n",
    "import NPZ\n",
    "import Statistics\n",
    "import Flux\n",
    "import CUDA\n",
    "import Zygote\n",
    "import Plots\n",
    "import BSON\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f86688",
   "metadata": {},
   "source": [
    "# Commandline Interface\n",
    "In anticipation of migrating to a normal julia file that will be run from commandline or by another programme.\n",
    "\n",
    "Note that some things offered by the argument parser have not (so far) been implemented. Specifically:\n",
    "* Use of a secondary gpu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7abcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emulating command line arguments to facilitate later migration from jupyter\n",
    "cli_args = split(\"-g 0 -m model_isotropic_02.jl -l /some/path/struc_brain_csv/label_data.csv /some/path/struc_brain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fbf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ArgParse\n",
    "settings = ArgParse.ArgParseSettings()\n",
    "ArgParse.@add_arg_table! settings begin\n",
    "    \"--training-gpu\", \"-g\"\n",
    "        help = \"gpu to use for training model\"\n",
    "        arg_type = Int\n",
    "        default = 0\n",
    "    \"--secondary-gpu\", \"-s\"\n",
    "        help = \"gpu to use for other tasks such as validation and testing (optional)\"\n",
    "        arg_type = Int\n",
    "    \"--model\", \"-m\"\n",
    "        help = \"which model to load\"\n",
    "        arg_type = String\n",
    "    \"--label-file\", \"-l\"\n",
    "        help = \"the file with the labels for the data, a data directory is given and this option isn't used <data-dir>/*.csv and <data-dir>/../*.csv will be tried\"\n",
    "        arg_type = String\n",
    "    \"data-dir\"\n",
    "        help = \"directory where the data is located\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3df3d8",
   "metadata": {},
   "source": [
    "# Hardcoded Paths\n",
    "Might in the future be modifiable via the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d481e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "const model_dir = \"/some/path/models\"    # Directory where Flux network models are kept\n",
    "const result_dir = \"/some/path/results\"  # Where results of a training go, including loadable\n",
    "                                                      # model objects with weights. Each training makes a\n",
    "                                                      # separate directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9c71e",
   "metadata": {},
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global out_fds = []\n",
    "\n",
    "function mprint(args...; kwargs...)\n",
    "    global out_fds\n",
    "    if !isdefined(@__MODULE__, :out_fds) || isnothing(out_fds) || isempty(out_fds)\n",
    "        # println(\"No valid output pool. Reverting to normal print\")\n",
    "    else\n",
    "        for ofd ∈ out_fds\n",
    "            redirect_stdout(() -> print(args...; kwargs...), ofd)\n",
    "            flush(ofd)\n",
    "        end\n",
    "    end\n",
    "    print(args...; kwargs...)\n",
    "end\n",
    "\n",
    "function mprintln(args...; kwargs...)\n",
    "    global out_fds\n",
    "    if !isdefined(@__MODULE__, :out_fds) || isnothing(out_fds) || isempty(out_fds)\n",
    "        # println(\"No valid output pool. Reverting to normal println\")\n",
    "        \n",
    "    else\n",
    "        for ofd ∈ out_fds\n",
    "            redirect_stdout(() -> println(args...; kwargs...), ofd)\n",
    "            flush(ofd)\n",
    "        end\n",
    "    end\n",
    "    println(args...; kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0207f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "function openfile(o)\n",
    "    println(\"Ignoring request to open $o\")\n",
    "end\n",
    "\n",
    "function openfile(pfile::AbstractString)\n",
    "    println(\"Received request to open $pfile\")\n",
    "    if isdir(dirname(pfile))\n",
    "        rv = open(pfile, \"w\")\n",
    "        println(\"File opened, returning filehandle\")\n",
    "        return rv\n",
    "    end\n",
    "end\n",
    "\n",
    "function openfile(pfd::IO)\n",
    "    println(\"Received request to open $pfd\")\n",
    "    if iswritable(pfd)\n",
    "        println(\"Is writable, returning as is\")\n",
    "        return pfd\n",
    "    end\n",
    "    println(\"Not writeble, ignoring\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "function closefile(o)\n",
    "    println(\"Ignoring request to close $o\")\n",
    "end\n",
    "\n",
    "function closefile(fd::IOStream)\n",
    "    println(\"Closing $fd\")\n",
    "    close(fd)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function withmultipleoutput(f, args...; kwargs...)\n",
    "    # Let's you use mprint(ln) to output to many streams.\n",
    "    # kwargs are currently ignored\n",
    "    # args can be filenames or IO objects, stdout should not be added (included by default)\n",
    "    #\n",
    "    # N.B. Don't nest! The files to write to are in a global variable!\n",
    "    #\n",
    "    global out_fds\n",
    "    push!(out_fds, (filter(x -> !isnothing(x), map(openfile, args)))...)\n",
    "    println(\"Entering \\\"with-multiple-output\\\"-context.\")\n",
    "    # println(\"out_fds ($(typeof(out_fds))):\")\n",
    "    # display(out_fds)\n",
    "    try\n",
    "        f()\n",
    "    finally\n",
    "        println(\"Leaving \\\"with-multiple-output\\\"-context. Closing appropriate files and resetting the output pool\")\n",
    "        # println(\"out_fds ($(typeof(out_fds))):\")\n",
    "        # display(out_fds)\n",
    "        map(closefile, out_fds)\n",
    "        out_fds = []\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db88ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "function fw_msg(fn)\n",
    "    mprintln(\"\\rFile written to path:\\n  '$fn'\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "tprint = Flux.throttle(print, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e9279",
   "metadata": {},
   "outputs": [],
   "source": [
    "function assign(dct,key,def)\n",
    "    if haskey(dct, key)\n",
    "        return dct[key]\n",
    "    elseif haskey(dct, Symbol(key))\n",
    "        return dct[Symbol(key)]\n",
    "    else\n",
    "        return def\n",
    "    end\n",
    "end\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360cdad0",
   "metadata": {},
   "source": [
    "# Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653c5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "function keyrecord(x)\n",
    "    chomp(x)\n",
    "    try\n",
    "        row = split(x, \",\")\n",
    "        k = parse(Int32, row[1])\n",
    "        v = collect(Float32, Iterators.map(x -> parse(Float32, x), row[2:end]))\n",
    "        return (k, v)\n",
    "    catch e\n",
    "        return (Int32(0), collect(Float32, (0.0, 0.0)))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "let partition = :train, vol_file_list = nothing\n",
    "    global load_data\n",
    "    function load_data(data_dir::String, label_file::String)\n",
    "        if !isdir(joinpath(data_dir, \".projections\"))\n",
    "            mkdir(joinpath(data_dir, \".projections\"))\n",
    "        end\n",
    "        labels = Dict(Iterators.map(keyrecord, eachline(label_file)))\n",
    "        delete!(labels, 0)\n",
    "        list_length = length(labels)\n",
    "        if partition == :train\n",
    "            start_p = Int32(1)                          # NB CHANGE BACK FOR \"PRODUCTION RUNS\" (I think...)\n",
    "            stop_p = round(Int32, list_length * 0.70f0) # 220908 Changing the split from 70/15/15 for\n",
    "            no_of_subs = stop_p                         # faster prototyping. New split  56/12/32\n",
    "            vol_file_list = collect(Iterators.filter(f -> contains(f, r\".nii.gz$\"), readdir(data_dir)))\n",
    "        end\n",
    "        if partition == :validation\n",
    "            start_p = round(Int32, list_length * 0.70f0) + Int32(1)\n",
    "            stop_p = round(Int32, list_length * 0.85f0)\n",
    "            no_of_subs = stop_p - start_p + Int32(1)\n",
    "        end\n",
    "        if partition == :test\n",
    "            start_p = round(Int32, list_length * 0.85f0) + Int32(1)\n",
    "            stop_p = round(Int32 ,list_length)\n",
    "            no_of_subs = stop_p - start_p + Int32(1)\n",
    "        end\n",
    "        X_trans = zeros(Float32, 256, 256, 2, no_of_subs)\n",
    "        X_coron = zeros(Float32, 208, 256, 2, no_of_subs)\n",
    "        X_sagit = zeros(Float32, 208, 256, 2, no_of_subs)\n",
    "        y = zeros(Float32, 2, no_of_subs)\n",
    "\n",
    "        Threads.@threads for (vol_no, fn) ∈ collect(enumerate(vol_file_list[start_p : stop_p]))\n",
    "            tprint(\"\\r$vol_no       \")\n",
    "            sub_id = parse( Int32, (match(r\"T1_(\\d+)_\", fn)).captures[1] )\n",
    "            @inbounds y[:, vol_no] = labels[sub_id]\n",
    "            vol = nothing\n",
    "            flush(stdout)\n",
    "            \n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.tr.npy\"))\n",
    "                xt = NPZ.npzread(joinpath(data_dir, \".projections/$fn.tr.npy\"))\n",
    "                @inbounds X_trans[:, :, :, vol_no] = xt\n",
    "            else\n",
    "                vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                xt = dropdims(cat(Statistics.mean(vol, dims=1), Statistics.std(vol, dims=1), dims=4), dims = 1)\n",
    "                @inbounds X_trans[:, :, :, vol_no] = xt\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.tr.npy\"), X_trans[:, :, :, vol_no])\n",
    "            end\n",
    "\n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.co.npy\"))\n",
    "                xc = NPZ.npzread(joinpath(data_dir, \".projections/$fn.co.npy\"))\n",
    "                @inbounds X_coron[:, :, :, vol_no] = xc\n",
    "            else\n",
    "                if isnothing(vol)\n",
    "                    vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                end\n",
    "                xc = dropdims(cat(Statistics.mean(vol, dims=2), Statistics.std(vol, dims=2), dims=4), dims = 2)\n",
    "                @inbounds X_coron[:, :, :, vol_no] = xc\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.co.npy\"), X_coron[:, :, :, vol_no])\n",
    "            end\n",
    "\n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.sa.npy\"))\n",
    "                xs = NPZ.npzread(joinpath(data_dir, \".projections/$fn.sa.npy\"))\n",
    "                @inbounds X_sagit[:, :, :, vol_no] = xs\n",
    "            else\n",
    "                if isnothing(vol)\n",
    "                    vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                end\n",
    "                xs = dropdims(cat(Statistics.mean(vol, dims=3), Statistics.std(vol, dims=3), dims=4), dims = 3)\n",
    "                @inbounds X_sagit[:, :, :, vol_no] = xs\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.sa.npy\"), X_sagit[:, :, :, vol_no])\n",
    "            end\n",
    "            #= This check is obviously inappropriate for a multithreaded solution\n",
    "            if vol_no == no_of_subs\n",
    "                break\n",
    "            end\n",
    "            =#\n",
    "        end #for statement\n",
    "        if partition == :train\n",
    "            partition = :validation\n",
    "        elseif partition == :validation\n",
    "            partition = :test\n",
    "        else\n",
    "            partition = :train\n",
    "        end\n",
    "        return (X_trans, X_coron, X_sagit, y)\n",
    "    end #function load_data\n",
    "end #let statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fd80e",
   "metadata": {},
   "source": [
    "# Model loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b365622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function canread(path::String)::Bool\n",
    "    if ccall((:access, \"libglib\"), Cint, (Cstring, Cint), path, 4) == 0\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_model(fn)\n",
    "    # NB! No longer returns the model\n",
    "    global model\n",
    "    mo = match(r\"\\.(bson|jl)$\"i, fn)\n",
    "    sfx = lowercase(mo[1])\n",
    "    if sfx == \"jl\"\n",
    "        Base.include(@__MODULE__, fn)\n",
    "        return make_my_model\n",
    "    elseif sfx == \"bson\"\n",
    "        BSON.@load fn model\n",
    "    else\n",
    "        throw(ErrorException(\"Executing unreachable code: out of cheese error\\nPlease restart universe!\"))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_weights(weights::Vector{Any}, mpath)\n",
    "    weights = weights |> Flux.cpu\n",
    "    ts = Dates.format(Dates.now(),\"yyyy-mm-dd-HH-MM-SS\")\n",
    "    mn = basename(mpath)\n",
    "    BSON.@save (model_dir * \"/model_$(mn)_$(ts)_weights.bson\") weights mpath ts\n",
    "    fw_msg(model_dir * \"/model_$(mn)_$(ts)_weights.bson\")\n",
    "end\n",
    "\n",
    "function save_weights(weights::Zygote.Params, mpath)\n",
    "    save_weights(collect(weights), mpath)\n",
    "end\n",
    "\n",
    "function save_weights(model, mpath)\n",
    "    # A model has a very complicated type signature, if we don't know what it is we assume it's a model.\n",
    "    save_weights(Flux.params(model), mpath)\n",
    "end\n",
    "\n",
    "function load_weights(fn)\n",
    "    BSON.@load fn weights mpath ts\n",
    "    return weights\n",
    "end\n",
    "\n",
    "function load_model_and_weights(fn)\n",
    "    # This function takes the file name of a file with weights. It is assumed that this file also correctly\n",
    "    # can identify which model it uses and reference the file from which to load it.\n",
    "    BSON.@load fn weights mpath ts\n",
    "    model = load_model(mpath)\n",
    "    Flux.loadparams!(model, weights)\n",
    "    model = model |> Flux.gpu\n",
    "    return model\n",
    "end\n",
    "\n",
    "function save_model(mpath, m = nothing, rdir = nothing)\n",
    "    # This is the new \".mdl.bson\" format.\n",
    "    if m == nothing\n",
    "        if @isdefined model\n",
    "            m = model\n",
    "        else\n",
    "            throw(Core.UndefVarError(\"Global model not defined and no other specified\"))\n",
    "        end\n",
    "    end\n",
    "    m = m |> Flux.cpu\n",
    "    ts = Dates.format(Dates.now(),\"yyyy-mm-dd-HH-MM-SS\")\n",
    "    mn = basename(mpath)\n",
    "    #BSON.bson(model_dir * \"/model_$(mn)_$(ts).mdl.bson\", Dict(:model => m))\n",
    "    #fw_msg(model_dir * \"/model_$(mn)_$(ts).mdl.bson\")\n",
    "    if !isnothing(rdir)\n",
    "        BSON.bson(rdir * \"/model_$(mn)_$(ts).mdl.bson\", Dict(:model => m))\n",
    "        fw_msg(rdir * \"/model_$(mn)_$(ts).mdl.bson\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47091aba",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6873ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.sum(x::Flux.Zeros) = Float32(0)\n",
    "\n",
    "Base.sum(f::Function, x::Flux.Zeros) = Float32(0)\n",
    "\n",
    "function my_loss(m, batch; kwargs...) # Not used right now because it is probably more convenient to keep the penalty separate\n",
    "    return Flux.mse(m(( batch.d₁ , batch.d₂ , batch.d₃ )), reshape(batch.l[1, :], 1, :)) + penalty(m)\n",
    "end\n",
    "\n",
    "function age_loss(m, batch; kwargs...)\n",
    "    return Flux.mse(m(( aug(batch.d₁) , aug(batch.d₂) , aug(batch.d₃) )), reshape(batch.l[1, :], 1, :))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_counter_funcs()\n",
    "    count = nothing\n",
    "    reset_count = nothing\n",
    "    let c = 1, tprint = Flux.throttle(print, 5)\n",
    "        function count()\n",
    "            tprint(\"\\r$c                                                                                 \")\n",
    "            c += 1\n",
    "        end\n",
    "        function reset_count()\n",
    "            c = 1\n",
    "        end\n",
    "    end\n",
    "    return (count, reset_count)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function mclean()\n",
    "    Flux.throttle(GC.gc, 37)\n",
    "end\n",
    "\n",
    "function mdeepclean()\n",
    "    Flux.throttle(() -> GC.gc(true), 1031)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import Base:isinteger\n",
    "function isinteger(x)\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b41e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_train!(model, loss, penalty, ps, data, opt; cb = () -> (), nob = nothing, kwargs...)\n",
    "    # Note that the kwargs are only there to pass directly to the loss function\n",
    "    ps = Zygote.Params(ps)\n",
    "    cb = Flux.Optimise.runall(cb)\n",
    "    if isinteger(nob)\n",
    "        l = Array{Float32, 1}(undef, nob)    \n",
    "    else      \n",
    "        l = []\n",
    "    end\n",
    "    history = Dict(:loss => l, :metrics => Dict(:penalty => []))\n",
    "    for (i, d) in enumerate(data)\n",
    "        try\n",
    "            # Below each batch is loaded separately onto the gpu as part of a hard-coded solution for augmentation\n",
    "            gs = Zygote.gradient(ps) do\n",
    "                l = loss(model, Flux.Optimise.batchmemaybe(d |> Flux.gpu)...; kwargs...) + penalty(model)\n",
    "            end                \n",
    "            if isinteger(nob)\n",
    "                history[:loss][i] = l\n",
    "            else          \n",
    "                push!(history[:loss], l)\n",
    "            end\n",
    "            push!(history[:metrics][:penalty], penalty(model))\n",
    "            Flux.update!(opt, ps, gs)\n",
    "            cb()\n",
    "        catch ex\n",
    "            if ex isa Flux.Optimise.StopException\n",
    "                break\n",
    "            elseif ex isa Flux.Optimise.SkipException\n",
    "                continue\n",
    "            else\n",
    "                rethrow(ex)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return history\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303b0a2",
   "metadata": {},
   "source": [
    "# Main procedure\n",
    "The code above is usually just run through to set up the framework. The code below define the individual runs to a higher degree.\n",
    "\n",
    "Having said that, if the runfromfile function is used, a lot of things could be varied merely by changes in the jobfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "myargs = ArgParse.parse_args(cli_args, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = myargs[\"label-file\"]\n",
    "data_dir = myargs[\"data-dir\"]\n",
    "CUDA.device!(myargs[\"training-gpu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102996c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans, X_coron, X_sagit, y = load_data(data_dir, label_file)\n",
    "X_trans_valid, X_coron_valid, X_sagit_valid, y_valid = load_data(data_dir, label_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"augment.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4faea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl1, pl2 = getpipeline(\"S X Y R E\")\n",
    "# So far, on-the-fly augmentation has turned out to be impractical\n",
    "# In stead I use the above to acquire an augmentation pipeline (using Scale, XShear, YShear, Rotation and Elastic deformation)\n",
    "# No numerical parameters means that I get (my) default values\n",
    "# Below I make a train_loader using said pipeline (really two, to accomodate the different dimensions of the proj's)\n",
    "train_loader = get_augment_loader((d₁ = X_trans, d₂ = X_coron, d₃ = X_sagit, l = y), 4, pl1, pl2)\n",
    "valid_loader = Flux.DataLoader((d₁ = X_trans_valid, d₂ = X_coron_valid, d₃ = X_sagit_valid, l = y_valid) , batchsize = 32, shuffle = false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcount, reset_bcount = get_counter_funcs()\n",
    "tcount, reset_tcount = get_counter_funcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f79fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 100\n",
    "no_of_k_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5cd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some default behaviors in the absence of certain features\n",
    "penalty(l) = 0 # When not using my custom convolution layer with advanced regularization\n",
    "aug = identity # When not using augmentation\n",
    "# include(\"models/model_01_reg_conv.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e505523",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"changelayers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02deff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_and_evaluate(mpath, arguments, modifications, hyperparameters; identifier=nothing)\n",
    "    best_val_loss = 30 # arbitrary cutoff for saving models based on val loss\n",
    "    IJulia.set_max_stdio(1 << 25)\n",
    "    aecs = (\"\\e[7m\", \"\\e[27m\")\n",
    "    make_my_model = load_model(mpath)\n",
    "    lr = assign(hyperparameters, \"lr\", 0.003)\n",
    "    wreg = assign(hyperparameters, \"wreg\", (0, 0))\n",
    "    areg = assign(hyperparameters, \"areg\", (0, 0))\n",
    "    # drate = assign(hyperparameters, \"drate\", 0.25) this is best done with modifications\n",
    "    result=\"\\e[38;2;0;255;0mWorks\\e[39m\"\n",
    "    try\n",
    "        model = make_my_model(arguments...;) |> Flux.gpu\n",
    "        for m ∈ modifications\n",
    "            println(\"Attempting to modify the model on the fly with $m $(supertypes(typeof(m)))\")\n",
    "            Base.invokelatest(m, model) # these could use changelayers from changelayers.jl but also do more drastic changes\n",
    "        end\n",
    "        if isnothing(identifier)\n",
    "            mn = basename(mpath) * \"_\" * join(map(k -> \"$(k)=$(hyperparameters[k])\", sort(collect(keys(hyperparameters)))), '_')\n",
    "        else\n",
    "            mn = identifier\n",
    "        end\n",
    "        \n",
    "        global_val_loss_curve = Vector{Float32}()\n",
    "        global_train_loss_curve = Vector{Float32}()\n",
    "        # Flux.loadparams!(model, ps_init |> Flux.gpu)\n",
    "        ps = Flux.params(model)\n",
    "        opt = Flux.ADAM(lr, (0.9, 0.999))\n",
    "        global_val_loss_curve = Vector{Float32}()\n",
    "        global_train_loss_curve = Vector{Float32}()\n",
    "        ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "        rdir = joinpath(result_dir, \"results_$(mn)_$(ts)_$(lr)\")\n",
    "        if !isdir(rdir)\n",
    "            mkdir(rdir)\n",
    "        end\n",
    "        withmultipleoutput(joinpath(rdir, \"train_log_$ts\")) do\n",
    "            mprintln(repr(\"text/plain\", model))\n",
    "            for k_epoch ∈ 1:no_of_k_epochs\n",
    "                val_losses = zeros(round(Int32, size(y_valid,2) / 32 + 0.5))\n",
    "                val_loss_curve = Array{Float32,1}(undef, no_of_epochs)\n",
    "                train_loss_curve = Array{Float32,1}(undef, no_of_epochs)\n",
    "                for ep ∈ 1:no_of_epochs\n",
    "                    Flux.trainmode!(model, true)\n",
    "                    h = my_train!(model, age_loss, penalty, ps, train_loader, opt; cb = [bcount, mclean, mdeepclean ])\n",
    "                    reset_bcount()\n",
    "                    train_loss_curve[ep] = Statistics.mean(h[:loss])\n",
    "                    mprint(\"\\rEpoch$(k_epoch).$(ep): running against validation set\")\n",
    "                    Flux.testmode!(model, true)\n",
    "                    for (i,b) in enumerate(valid_loader)\n",
    "                        val_losses[i] = age_loss(model, b |> Flux.gpu) # This bit ought to be harmless but isn't needed any more\n",
    "                    end\n",
    "                    mprint(\"\\r                                                     \")\n",
    "                    val_loss_curve[ep] = Statistics.mean(val_losses)\n",
    "                    if val_loss_curve[ep] < best_val_loss\n",
    "                        best_val_loss = val_loss_curve[ep]\n",
    "                        save_model(mpath * \"_val_loss=$(best_val_loss)@epoch_$(ep)\", model, rdir)\n",
    "                    end\n",
    "                    ts = Dates.format(Dates.now(),\"yyyy-mm-dd@HH:MM:SS\")\n",
    "                    if ep % 200 == 0\n",
    "                        mprintln(\"\\r$ts: This is epoch $((k_epoch - 1) * no_of_epochs + ep) and validation loss was $(val_loss_curve[ep]) while training loss was $(train_loss_curve[ep])\")\n",
    "                    end\n",
    "                end\n",
    "                Plots.plot(train_loss_curve)\n",
    "                Plots.plot!(val_loss_curve)\n",
    "                ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "                Plots.savefig(rdir * \"/k_epoch_plot_$(k_epoch)_$(mn)_$(ts)_$(lr).png\")\n",
    "                fw_msg(rdir * \"/k_epoch_plot_$(k_epoch)_$(mn)_$(ts)_$(lr).png\")\n",
    "                save_model(mpath, model, rdir)\n",
    "                append!(global_train_loss_curve, train_loss_curve)\n",
    "                append!(global_val_loss_curve, val_loss_curve)\n",
    "            end\n",
    "            Plots.plot(global_train_loss_curve)\n",
    "            Plots.plot!(global_val_loss_curve)\n",
    "            ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "            Plots.savefig(rdir * \"/global_plot_$(mn)_$(ts)_$(lr).png\")\n",
    "            fw_msg(rdir * \"/global_plot_$(mn)_$(ts)_$(lr).png\")\n",
    "            mprintln(\"\\nPreparing to save accumulated learning data\")\n",
    "            gt_min = minimum(global_train_loss_curve)\n",
    "            gt_end = global_train_loss_curve[end]\n",
    "            gv_min = minimum(global_val_loss_curve)\n",
    "            gv_end = global_val_loss_curve[end]\n",
    "            mprintln(\"Saving accumulated learning data\")\n",
    "            BSON.@save (rdir * \"/global_loss_$(mn)_$(ts)_$(lr)___$(gv_min)_$(gv_end)_$(gt_min)_$(gt_end).bson\") global_train_loss_curve global_val_loss_curve\n",
    "            fw_msg(rdir * \"/global_loss_$(mn)_$(ts)_$(lr)___$(gv_min)_$(gv_end)_$(gt_min)_$(gt_end).bson\")\n",
    "            mprintln(\"Accumulated learning data saved\")\n",
    "        end\n",
    "\n",
    "    catch e\n",
    "        result=\"\\e[38;2;255;0;0mCrashes ($(typeof(e)))\\e[39m \"*repr(MIME(\"text/plain\"), e)\n",
    "        mprintln(\"\\n\",e,\"\\n\")\n",
    "        flush(stdout)\n",
    "        for sf in stacktrace(catch_backtrace())\n",
    "            display(sf)\n",
    "            mprintln()\n",
    "            flush(stdout)\n",
    "        end\n",
    "        if e isa InterruptException\n",
    "            rethrow()\n",
    "        end\n",
    "    finally\n",
    "        mprintln(\"\\r\", \"\", \"\\t\", result)\n",
    "        mprint(\"\\n\\e[38;2;0;0;0;48;2;255;255;0m\")\n",
    "        for i ∈ 0:11\n",
    "            mprint(\" ▁▂▃▄▅▆▇█\" * aecs[1 + i % 2])\n",
    "        end\n",
    "        mprintln(\"\\e[0m\\n\")\n",
    "    end\n",
    "\n",
    "end # end train_and_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include(\"hpiterator.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7543638",
   "metadata": {},
   "outputs": [],
   "source": [
    "function runfromfile(fn)\n",
    "    # This function takes the name of a file\n",
    "    # It runs ONE training from the file if it finds one suitable\n",
    "    # and deletes the description of that training from the file\n",
    "    # The trainings are described as a line containing:\n",
    "    # <gpu> args=<arguments> kwargs=<keyword arguments>\n",
    "    # where <gpu> is the device number (typically 0, 1 etc)\n",
    "    # args and kwargs are passed to the train_and_evaluate function\n",
    "    lines = open(readlines, fn, \"r\") \n",
    "    # the file is read and closed but a race condition can exist if a processes read the file\n",
    "    # before another one has closed it. This can lead to repeating runs or perhaps dropping some.\n",
    "    # This simply has to be monitored afterwards.\n",
    "    forbiddenkeywords = [:aug, :augmentation, \"aug\", \"augmentation\", ] # things that might show up in the run file but should be dealt with elsewhere\n",
    "\n",
    "    lines_before = Vector{eltype(lines)}()\n",
    "    lines_after = Vector{eltype(lines)}()\n",
    "    cur = nothing\n",
    "    for idx ∈ 1:length(lines) # I know lines doesn't use \"exotic\" indexing\n",
    "        mo = match(r\"^(\\d+)\\D+\", lines[idx])\n",
    "        if !isnothing(mo) # && parse(Int32, mo[1]) % 3 == CUDA.device().handle #Run any job\n",
    "            cur = idx\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if isnothing(cur)\n",
    "        return false\n",
    "    else\n",
    "        lines_before = lines[1:cur-1]\n",
    "        lines_after = lines[cur+1:end]\n",
    "        open(f->println(f, join(cat(lines_before, lines_after; dims = (1,)), \"\\n\")) , fn, \"w\")\n",
    "        # now the file is written and closed and the race condition over.\n",
    "        line = lines[cur]\n",
    "        mo = match(r\"^(\\d+)\\s+args\\s*=\\s*(.*?)\\s*kwargs\\s*=\\s*(.*)\\s*$\", line)\n",
    "        println(\"mo = $mo\")\n",
    "        if isnothing(mo)\n",
    "            mo = match(r\"^(\\d+)?(\\s+)?(args)?(\\s*)(=)?(\\s*)(.+?\\))?(\\s*)(kwargs)?(\\s*)(=)?(\\s*)(.*)(\\s*)($)?\", line)\n",
    "            if isnothing(mo)\n",
    "                ei = 1\n",
    "            else\n",
    "                println(\"mo = $mo\")\n",
    "                egr = nothing\n",
    "                for gr = 1:13\n",
    "                    if isnothing(mo[gr])\n",
    "                        egr = gr\n",
    "                        println(\"egr = $egr\")\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "                if isnothing(egr) || egr == 1\n",
    "                    ei = 1\n",
    "                else\n",
    "                    ei = mo.offsets[egr - 1] + length(mo[egr - 1])\n",
    "                end\n",
    "            end\n",
    "            markerline = \"\\e[1;38;5;255;255;0m\" * \"─\" ^ (ei - 1) * \"\\e[5m⬏\\e[0m\"\n",
    "            throw(ErrorException(\"Line $idx in $fn does not conform to the syntax.\\n\\n$line\\n$markerline\"))\n",
    "        else\n",
    "            args = eval(Meta.parse(mo[2]))\n",
    "            kwargs = eval(Meta.parse(mo[3]))\n",
    "            for kw in forbiddenkeywords\n",
    "                delete!(kwargs, kw)\n",
    "            end\n",
    "            println(\"Attempting to run train_and_evaluate(args...; kwargs...) with\\n    args   = $args\\n    kwargs = $kwargs\")\n",
    "            train_and_evaluate(args...; kwargs...)\n",
    "        end\n",
    "        return true\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1c7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobfile=\"some/file\"\n",
    "toc = Inf64\n",
    "while toc > 6000000000000\n",
    "    tic = time_ns()\n",
    "    # below is an attempt at a workaround for some hard to understand world age / CUDA interactions\n",
    "    nextline = readline(jobfile)\n",
    "    mo = match(r\"\\\"([^\\\"]+)\\\"\", nextline)\n",
    "    if ! isnothing(mo)\n",
    "        mfn = mo[1]\n",
    "        load_model(mfn)\n",
    "    end\n",
    "    # End of workaround\n",
    "    runfromfile(jobfile)\n",
    "    toc = time_ns() - tic\n",
    "    println(\"toc = $toc ($(round(Int32, toc / 10 ^ 9)) s)\\n\\n\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia (36t) 1.6.4",
   "language": "julia",
   "name": "julia-(36t)-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
