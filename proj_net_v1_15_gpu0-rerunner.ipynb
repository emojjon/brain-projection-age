{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde2df3f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d45e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m environment at `~/3Dto2D/v1/Project.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795bdcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Main.CodeInfo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ArgParse\n",
    "import Dates\n",
    "import NIfTI\n",
    "import NPZ\n",
    "import Statistics\n",
    "import Flux\n",
    "import CUDA\n",
    "import Zygote\n",
    "import Plots\n",
    "import BSON\n",
    "import Augmentor\n",
    "include(\"/home/johjo50/.julia/mycode/codeinfo.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f86688",
   "metadata": {},
   "source": [
    "# Commandline Interface\n",
    "In anticipation of migrating to a normal julia file that will be run from commandline or by another programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7abcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Vector{SubString{String}}:\n",
       " \"-g\"\n",
       " \"0\"\n",
       " \"-m\"\n",
       " \"model_isotropic_02.jl\"\n",
       " \"-l\"\n",
       " \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan_csv/label_data.csv\"\n",
       " \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emulating command line arguments to facilitate later migration from jupyter\n",
    "cli_args = split(\"-g 0 -m model_isotropic_02.jl -l /flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan_csv/label_data.csv /flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8fbf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArgParseSettings(\n",
       "  prog=\n",
       "  description=\n",
       "  epilog=\n",
       "  usage=\n",
       "  version=Unspecified version\n",
       "  add_help=true\n",
       "  add_version=false\n",
       "  fromfile_prefix_chars=Set{Char}()\n",
       "  autofix_names=false\n",
       "  error_on_conflict=true\n",
       "  suppress_warnings=false\n",
       "  allow_ambiguous_opts=false\n",
       "  commands_are_required=true\n",
       "  default_group=\n",
       "  exc_handler=default_handler\n",
       "  preformatted_description=false\n",
       "  preformatted_epilog=false\n",
       "  exit_after_help=false\n",
       "  >> usage: <PROGRAM> [-g TRAINING-GPU] [-s SECONDARY-GPU] [-m MODEL]\n",
       "                 [-l LABEL-FILE] [data-dir]\n",
       "  )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ArgParse\n",
    "settings = ArgParse.ArgParseSettings()\n",
    "ArgParse.@add_arg_table! settings begin\n",
    "    \"--training-gpu\", \"-g\"\n",
    "        help = \"gpu to use for training model\"\n",
    "        arg_type = Int\n",
    "        default = 0\n",
    "    \"--secondary-gpu\", \"-s\"\n",
    "        help = \"gpu to use for other tasks such as validation and testing (optional)\"\n",
    "        arg_type = Int\n",
    "    \"--model\", \"-m\"\n",
    "        help = \"which model to load\"\n",
    "        arg_type = String\n",
    "    \"--label-file\", \"-l\"\n",
    "        help = \"the file with the labels for the data, a data directory is given and this option isn't used <data-dir>/*.csv and <data-dir>/../*.csv will be tried\"\n",
    "        arg_type = String\n",
    "    \"data-dir\"\n",
    "        help = \"directory where the data is located\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3df3d8",
   "metadata": {},
   "source": [
    "# Hardcoded Paths\n",
    "Might in the future be modifiable via the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d481e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/johjo50/3Dto2D/v1/results\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const label_file = \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan_csv/label_data.csv\"\n",
    "const data_dir = \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan\"\n",
    "const model_dir = \"/home/johjo50/3Dto2D/v1/models\"\n",
    "const result_dir = \"/home/johjo50/3Dto2D/v1/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9c71e",
   "metadata": {},
   "source": [
    "# General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3145054c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mprintln (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global out_fds = []\n",
    "\n",
    "function mprint(args...; kwargs...)\n",
    "    global out_fds\n",
    "    if !isdefined(@__MODULE__, :out_fds) || isnothing(out_fds) || isempty(out_fds)\n",
    "        # println(\"No valid output pool. Reverting to normal print\")\n",
    "    else\n",
    "        for ofd ∈ out_fds\n",
    "            redirect_stdout(() -> print(args...; kwargs...), ofd)\n",
    "            flush(ofd)\n",
    "        end\n",
    "    end\n",
    "    print(args...; kwargs...)\n",
    "end\n",
    "\n",
    "function mprintln(args...; kwargs...)\n",
    "    global out_fds\n",
    "    if !isdefined(@__MODULE__, :out_fds) || isnothing(out_fds) || isempty(out_fds)\n",
    "        # println(\"No valid output pool. Reverting to normal println\")\n",
    "        \n",
    "    else\n",
    "        for ofd ∈ out_fds\n",
    "            redirect_stdout(() -> println(args...; kwargs...), ofd)\n",
    "            flush(ofd)\n",
    "        end\n",
    "    end\n",
    "    println(args...; kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0207f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openfile (generic function with 3 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function openfile(o)\n",
    "    println(\"Ignoring request to open $o\")\n",
    "end\n",
    "\n",
    "function openfile(pfile::AbstractString)\n",
    "    println(\"Received request to open $pfile\")\n",
    "    if isdir(dirname(pfile))\n",
    "        rv = open(pfile, \"w\")\n",
    "        println(\"File opened, returning filehandle\")\n",
    "        return rv\n",
    "    end\n",
    "end\n",
    "\n",
    "function openfile(pfd::IO)\n",
    "    println(\"Received request to open $pfd\")\n",
    "    if iswritable(pfd)\n",
    "        println(\"Is writable, returning as is\")\n",
    "        return pfd\n",
    "    end\n",
    "    println(\"Not writeble, ignoring\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d30c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closefile (generic function with 2 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function closefile(o)\n",
    "    println(\"Ignoring request to close $o\")\n",
    "end\n",
    "\n",
    "function closefile(fd::IOStream)\n",
    "    println(\"Closing $fd\")\n",
    "    close(fd)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764a2ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "withmultipleoutput (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function withmultipleoutput(f, args...; kwargs...)\n",
    "    # Let's you use mprint(ln) to output to many streams.\n",
    "    # kwargs are currently ignored\n",
    "    # args can be filenames or IO objects, stdout should not be added (included by default)\n",
    "    #\n",
    "    # N.B. Don't nest! The files to write to are in a global variable!\n",
    "    #\n",
    "    global out_fds\n",
    "    push!(out_fds, (filter(x -> !isnothing(x), map(openfile, args)))...)\n",
    "    println(\"Entering \\\"with-multiple-output\\\"-context.\")\n",
    "    # println(\"out_fds ($(typeof(out_fds))):\")\n",
    "    # display(out_fds)\n",
    "    try\n",
    "        f()\n",
    "    finally\n",
    "        println(\"Leaving \\\"with-multiple-output\\\"-context. Closing appropriate files and resetting the output pool\")\n",
    "        # println(\"out_fds ($(typeof(out_fds))):\")\n",
    "        # display(out_fds)\n",
    "        map(closefile, out_fds)\n",
    "        out_fds = []\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67db88ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fw_msg (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fw_msg(fn)\n",
    "    mprintln(\"\\rFile written to path:\\n  '$fn'\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b2a203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::Flux.var\"#throttled#122\"{Flux.var\"#throttled#118#123\"{Bool, Bool, typeof(print), Int64}}) (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both Losses and NNlib export \"ctc_loss\"; uses of it in module Flux must be qualified\n"
     ]
    }
   ],
   "source": [
    "tprint = Flux.throttle(print, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2e9279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assign (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function assign(dct,key,def)\n",
    "    if haskey(dct, key)\n",
    "        return dct[key]\n",
    "    elseif haskey(dct, Symbol(key))\n",
    "        return dct[Symbol(key)]\n",
    "    else\n",
    "        return def\n",
    "    end\n",
    "end\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360cdad0",
   "metadata": {},
   "source": [
    "# Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "653c5557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyrecord (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function keyrecord(x)\n",
    "    chomp(x)\n",
    "    try\n",
    "        row = split(x, \",\")\n",
    "        k = parse(Int32, row[1])\n",
    "        v = collect(Float32, Iterators.map(x -> parse(Float32, x), row[2:end]))\n",
    "        return (k, v)\n",
    "    catch e\n",
    "        return (Int32(0), collect(Float32, (0.0, 0.0)))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "256e6bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_data (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let partition = :train, vol_file_list = nothing\n",
    "    global load_data\n",
    "    function load_data(data_dir::String, label_file::String)\n",
    "        if !isdir(joinpath(data_dir, \".projections\"))\n",
    "            mkdir(joinpath(data_dir, \".projections\"))\n",
    "        end\n",
    "        labels = Dict(Iterators.map(keyrecord, eachline(label_file)))\n",
    "        delete!(labels, 0)\n",
    "        list_length = length(labels)\n",
    "        if partition == :train\n",
    "            start_p = Int32(1)                          # NB CHANGE BACK FOR \"PRODUCTION RUNS\" (I think...)\n",
    "            stop_p = round(Int32, list_length * 0.70f0) # 220908 Changing the split from 70/15/15 for\n",
    "            no_of_subs = stop_p                         # faster prototyping. New split  56/12/32\n",
    "            vol_file_list = collect(Iterators.filter(f -> contains(f, r\".nii.gz$\"), readdir(data_dir)))\n",
    "        end\n",
    "        if partition == :validation\n",
    "            start_p = round(Int32, list_length * 0.70f0) + Int32(1)\n",
    "            stop_p = round(Int32, list_length * 0.85f0)\n",
    "            no_of_subs = stop_p - start_p + Int32(1)\n",
    "        end\n",
    "        if partition == :test\n",
    "            start_p = round(Int32, list_length * 0.85f0) + Int32(1)\n",
    "            stop_p = round(Int32 ,list_length)\n",
    "            no_of_subs = stop_p - start_p + Int32(1)\n",
    "        end\n",
    "        X_trans = zeros(Float32, 256, 256, 2, no_of_subs)\n",
    "        X_coron = zeros(Float32, 208, 256, 2, no_of_subs)\n",
    "        X_sagit = zeros(Float32, 208, 256, 2, no_of_subs)\n",
    "        y = zeros(Float32, 2, no_of_subs)\n",
    "\n",
    "        Threads.@threads for (vol_no, fn) ∈ collect(enumerate(vol_file_list[start_p : stop_p]))\n",
    "            tprint(\"\\r$vol_no       \")\n",
    "            sub_id = parse( Int32, (match(r\"T1_(\\d+)_\", fn)).captures[1] )\n",
    "            @inbounds y[:, vol_no] = labels[sub_id]\n",
    "            vol = nothing\n",
    "            flush(stdout)\n",
    "            \n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.tr.npy\"))\n",
    "                xt = NPZ.npzread(joinpath(data_dir, \".projections/$fn.tr.npy\"))\n",
    "                @inbounds X_trans[:, :, :, vol_no] = xt\n",
    "            else\n",
    "                vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                xt = dropdims(cat(Statistics.mean(vol, dims=1), Statistics.std(vol, dims=1), dims=4), dims = 1)\n",
    "                @inbounds X_trans[:, :, :, vol_no] = xt\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.tr.npy\"), X_trans[:, :, :, vol_no])\n",
    "            end\n",
    "\n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.co.npy\"))\n",
    "                xc = NPZ.npzread(joinpath(data_dir, \".projections/$fn.co.npy\"))\n",
    "                @inbounds X_coron[:, :, :, vol_no] = xc\n",
    "            else\n",
    "                if isnothing(vol)\n",
    "                    vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                end\n",
    "                xc = dropdims(cat(Statistics.mean(vol, dims=2), Statistics.std(vol, dims=2), dims=4), dims = 2)\n",
    "                @inbounds X_coron[:, :, :, vol_no] = xc\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.co.npy\"), X_coron[:, :, :, vol_no])\n",
    "            end\n",
    "\n",
    "            if isfile(joinpath(data_dir, \".projections/$fn.sa.npy\"))\n",
    "                xs = NPZ.npzread(joinpath(data_dir, \".projections/$fn.sa.npy\"))\n",
    "                @inbounds X_sagit[:, :, :, vol_no] = xs\n",
    "            else\n",
    "                if isnothing(vol)\n",
    "                    vol = NIfTI.niread(joinpath(data_dir, fn)).raw\n",
    "                end\n",
    "                xs = dropdims(cat(Statistics.mean(vol, dims=3), Statistics.std(vol, dims=3), dims=4), dims = 3)\n",
    "                @inbounds X_sagit[:, :, :, vol_no] = xs\n",
    "                NPZ.npzwrite(joinpath(data_dir, \".projections/$fn.sa.npy\"), X_sagit[:, :, :, vol_no])\n",
    "            end\n",
    "            #= This check is obviously inappropriate for a multithreaded solution\n",
    "            if vol_no == no_of_subs\n",
    "                break\n",
    "            end\n",
    "            =#\n",
    "        end #for statement\n",
    "        if partition == :train\n",
    "            partition = :validation\n",
    "        elseif partition == :validation\n",
    "            partition = :test\n",
    "        else\n",
    "            partition = :train\n",
    "        end\n",
    "        return (X_trans, X_coron, X_sagit, y)\n",
    "    end #function load_data\n",
    "end #let statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fd80e",
   "metadata": {},
   "source": [
    "# Model loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b365622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canread (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function canread(path::String)::Bool\n",
    "    if ccall((:access, \"libglib\"), Cint, (Cstring, Cint), path, 4) == 0\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e2f080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_model (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_model(fn)\n",
    "    # NB! No longer returns the model\n",
    "    global model\n",
    "    mo = match(r\"\\.(bson|jl)$\"i, fn)\n",
    "    sfx = lowercase(mo[1])\n",
    "    if sfx == \"jl\"\n",
    "        Base.include(@__MODULE__, fn)\n",
    "        return make_my_model\n",
    "    elseif sfx == \"bson\"\n",
    "        BSON.@load fn model\n",
    "    else\n",
    "        throw(ErrorException(\"Executing unreachable code: out of cheese error\\nPlease restart universe!\"))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870c2a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save_model (generic function with 3 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function save_weights(weights::Vector{Any}, mpath)\n",
    "    weights = weights |> Flux.cpu\n",
    "    ts = Dates.format(Dates.now(),\"yyyy-mm-dd-HH-MM-SS\")\n",
    "    mn = basename(mpath)\n",
    "    BSON.@save (model_dir * \"/model_$(mn)_$(ts)_weights.bson\") weights mpath ts\n",
    "    fw_msg(model_dir * \"/model_$(mn)_$(ts)_weights.bson\")\n",
    "end\n",
    "\n",
    "function save_weights(weights::Zygote.Params, mpath)\n",
    "    save_weights(collect(weights), mpath)\n",
    "end\n",
    "\n",
    "function save_weights(model, mpath)\n",
    "    # A model has a very complicated type signature, if we don't know what it is we assume it's a model.\n",
    "    save_weights(Flux.params(model), mpath)\n",
    "end\n",
    "\n",
    "function load_weights(fn)\n",
    "    BSON.@load fn weights mpath ts\n",
    "    return weights\n",
    "end\n",
    "\n",
    "function load_model_and_weights(fn)\n",
    "    # This function takes the file name of a file with weights. It is assumed that this file also correctly\n",
    "    # can identify which model it uses and reference the file from which to load it.\n",
    "    BSON.@load fn weights mpath ts\n",
    "    model = load_model(mpath)\n",
    "    Flux.loadparams!(model, weights)\n",
    "    model = model |> Flux.gpu\n",
    "    return model\n",
    "end\n",
    "\n",
    "function save_model(mpath, m = nothing, rdir = nothing)\n",
    "    # This is the new \".mdl.bson\" format.\n",
    "    if m == nothing\n",
    "        if @isdefined model\n",
    "            m = model\n",
    "        else\n",
    "            throw(Core.UndefVarError(\"Global model not defined and no other specified\"))\n",
    "        end\n",
    "    end\n",
    "    m = m |> Flux.cpu\n",
    "    ts = Dates.format(Dates.now(),\"yyyy-mm-dd-HH-MM-SS\")\n",
    "    mn = basename(mpath)\n",
    "    #BSON.bson(model_dir * \"/model_$(mn)_$(ts).mdl.bson\", Dict(:model => m))\n",
    "    #fw_msg(model_dir * \"/model_$(mn)_$(ts).mdl.bson\")\n",
    "    if !isnothing(rdir)\n",
    "        BSON.bson(rdir * \"/model_$(mn)_$(ts).mdl.bson\", Dict(:model => m))\n",
    "        fw_msg(rdir * \"/model_$(mn)_$(ts).mdl.bson\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47091aba",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6873ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Base.sum(x::Flux.Zeros) = Float32(0)\n",
    "\n",
    "Base.sum(f::Function, x::Flux.Zeros) = Float32(0)\n",
    "\n",
    "function my_loss(m, batch; kwargs...) # Not used right now because it is probably more convenient to keep the penalty separate\n",
    "    return Flux.mse(m(( batch.d₁ , batch.d₂ , batch.d₃ )), reshape(batch.l[1, :], 1, :)) + penalty(m)\n",
    "end\n",
    "\n",
    "function age_loss(m, batch; kwargs...)\n",
    "    return Flux.mse(m(( aug(batch.d₁) , aug(batch.d₂) , aug(batch.d₃) )), reshape(batch.l[1, :], 1, :))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "896fd12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_counter_funcs (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_counter_funcs()\n",
    "    count = nothing\n",
    "    reset_count = nothing\n",
    "    let c = 1, tprint = Flux.throttle(print, 5)\n",
    "        function count()\n",
    "            tprint(\"\\r$c                                                                                 \")\n",
    "            c += 1\n",
    "        end\n",
    "        function reset_count()\n",
    "            c = 1\n",
    "        end\n",
    "    end\n",
    "    return (count, reset_count)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a0d5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mdeepclean (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mclean()\n",
    "    Flux.throttle(GC.gc, 37)\n",
    "end\n",
    "\n",
    "function mdeepclean()\n",
    "    Flux.throttle(() -> GC.gc(true), 1031)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6993fa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isinteger (generic function with 10 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import Base:isinteger\n",
    "function isinteger(x)\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20b41e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_train! (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_train!(model, loss, penalty, ps, data, opt; cb = () -> (), nob = nothing, kwargs...)\n",
    "    # Note that the kwargs are only there to pass directly to the loss function\n",
    "    ps = Zygote.Params(ps)\n",
    "    cb = Flux.Optimise.runall(cb)\n",
    "    if isinteger(nob)\n",
    "        l = Array{Float32, 1}(undef, nob)    \n",
    "    else      \n",
    "        l = []\n",
    "    end\n",
    "    history = Dict(:loss => l, :metrics => Dict(:penalty => []))\n",
    "    for (i, d) in enumerate(data)\n",
    "        try\n",
    "            # Below each batch is loaded separately onto the gpu as part of a hard-coded solution for augmentation\n",
    "            gs = Zygote.gradient(ps) do\n",
    "                l = loss(model, Flux.Optimise.batchmemaybe(d |> Flux.gpu)...; kwargs...) + penalty(model)\n",
    "            end                \n",
    "            if isinteger(nob)\n",
    "                history[:loss][i] = l\n",
    "            else          \n",
    "                push!(history[:loss], l)\n",
    "            end\n",
    "            push!(history[:metrics][:penalty], penalty(model))\n",
    "            Flux.update!(opt, ps, gs)\n",
    "            cb()\n",
    "        catch ex\n",
    "            if ex isa Flux.Optimise.StopException\n",
    "                break\n",
    "            elseif ex isa Flux.Optimise.SkipException\n",
    "                continue\n",
    "            else\n",
    "                rethrow(ex)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return history\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303b0a2",
   "metadata": {},
   "source": [
    "# Main procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "732c84ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 5 entries:\n",
       "  \"label-file\"    => \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan_csv…\n",
       "  \"data-dir\"      => \"/flush/common/UKbiobank/T1_dset/struc_brain_HCC_Johan\"\n",
       "  \"secondary-gpu\" => nothing\n",
       "  \"model\"         => \"model_isotropic_02.jl\"\n",
       "  \"training-gpu\"  => 0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myargs = ArgParse.parse_args(cli_args, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6e81de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(0): Quadro RTX 8000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.device!(myargs[\"training-gpu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102996c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "18633       \r",
      "2261       \r",
      "10171       \r",
      "3391       \r",
      "1131       \r",
      "6216       \r",
      "5086       \r",
      "19761       \r",
      "14121       \r",
      "15813       "
     ]
    }
   ],
   "source": [
    "X_trans, X_coron, X_sagit, y = load_data(data_dir, label_file)\n",
    "X_trans_valid, X_coron_valid, X_sagit_valid, y_valid = load_data(data_dir, label_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d0b8507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_augment_loader (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"augment.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d4faea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found parameter group 'S'\n",
      "Exiting inner augmentation parsing loop, rest of group configuration string is ''\n",
      "Found parameter group 'X'\n",
      "Exiting inner augmentation parsing loop, rest of group configuration string is ''\n",
      "Found parameter group 'Y'\n",
      "Exiting inner augmentation parsing loop, rest of group configuration string is ''\n",
      "Found parameter group 'R'\n",
      "Exiting inner augmentation parsing loop, rest of group configuration string is ''\n",
      "Found parameter group 'E'\n",
      "Exiting inner augmentation parsing loop, rest of group configuration string is ''\n",
      "Exiting outer augmentation parsing loop, rest of configuration string is ''\n",
      "Scale parameters not understood ('Float32[]'), using default range 1.01:0.05:1.2\n",
      "Parameters for shearing along X-axis not understood ('Float32[]'), using default range -5.0:5.0\n",
      "Parameters for shearing along Y-axis not understood ('Float32[]'), using default range -5.0:5.0\n",
      "Rotation parameters not understood ('Float32[]'), using default range -5.0:5.0\n",
      "Parameters for elastic distortion not understood ('Float32[]'), using default: ElasticDistortion(4, 4, 0.1, 4)\n",
      "Augmenting the training data\n",
      "time\tsize\n",
      "11087\t 81297                          "
     ]
    }
   ],
   "source": [
    "pl1, pl2 = getpipeline(\"S X Y R E\")\n",
    "# So far, on-the-fly augmentation has turned out to be impractical\n",
    "# In stead I use the above to acquire an augmentation pipeline (using Scale, XShear, YShear, Rotation and Elastic deformation)\n",
    "# No numerical parameters means that I get (my) default values\n",
    "# Below I make a train_loader using said pipeline (really two, to accomodate the different dimensions of the proj's)\n",
    "train_loader = get_augment_loader((d₁ = X_trans, d₂ = X_coron, d₃ = X_sagit, l = y), 4, pl1, pl2)\n",
    "valid_loader = Flux.DataLoader((d₁ = X_trans_valid, d₂ = X_coron_valid, d₃ = X_sagit_valid, l = y_valid) , batchsize = 32, shuffle = false);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "731c6696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(var\"#count#17\"{Flux.var\"#throttled#122\"{Flux.var\"#throttled#118#123\"{Bool, Bool, typeof(print), Int64}}}(Core.Box(1), Flux.var\"#throttled#122\"{Flux.var\"#throttled#118#123\"{Bool, Bool, typeof(print), Int64}}(Flux.var\"#throttled#118#123\"{Bool, Bool, typeof(print), Int64}(true, false, print, 5, Core.Box(nothing), Core.Box(nothing), Core.Box(true)))), var\"#reset_count#18\"(Core.Box(1)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcount, reset_bcount = get_counter_funcs()\n",
    "tcount, reset_tcount = get_counter_funcs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15f79fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_epochs = 100\n",
    "no_of_k_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc5cd477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "identity (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some default behaviors in the absence of certain features\n",
    "penalty(l) = 0 # When not using my custom convolution layer with advanced regularization\n",
    "aug = identity # When not using augmentation\n",
    "# include(\"models/model_01_reg_conv.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e505523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"changelayers.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02deff17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_and_evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_and_evaluate(mpath, arguments, modifications, hyperparameters; identifier=nothing)\n",
    "    best_val_loss = 30 # arbitrary cutoff for saving models based on val loss\n",
    "    IJulia.set_max_stdio(1 << 25)\n",
    "    aecs = (\"\\e[7m\", \"\\e[27m\")\n",
    "    make_my_model = load_model(mpath)\n",
    "    lr = assign(hyperparameters, \"lr\", 0.003)\n",
    "    wreg = assign(hyperparameters, \"wreg\", (0, 0))\n",
    "    areg = assign(hyperparameters, \"areg\", (0, 0))\n",
    "    # drate = assign(hyperparameters, \"drate\", 0.25) this is best done with modifications\n",
    "    result=\"\\e[38;2;0;255;0mWorks\\e[39m\"\n",
    "    try\n",
    "        model = make_my_model(arguments...;) |> Flux.gpu\n",
    "        for m ∈ modifications\n",
    "            println(\"Attempting to modify the model on the fly with $m $(supertypes(typeof(m)))\")\n",
    "            Base.invokelatest(m, model) # these could use changelayers from changelayers.jl but also do more drastic changes\n",
    "        end\n",
    "        if isnothing(identifier)\n",
    "            mn = basename(mpath) * \"_\" * join(map(k -> \"$(k)=$(hyperparameters[k])\", sort(collect(keys(hyperparameters)))), '_')\n",
    "        else\n",
    "            mn = identifier\n",
    "        end\n",
    "        \n",
    "        global_val_loss_curve = Vector{Float32}()\n",
    "        global_train_loss_curve = Vector{Float32}()\n",
    "        # Flux.loadparams!(model, ps_init |> Flux.gpu)\n",
    "        ps = Flux.params(model)\n",
    "        opt = Flux.ADAM(lr, (0.9, 0.999))\n",
    "        global_val_loss_curve = Vector{Float32}()\n",
    "        global_train_loss_curve = Vector{Float32}()\n",
    "        ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "        rdir = joinpath(result_dir, \"results_$(mn)_$(ts)_$(lr)\")\n",
    "        if !isdir(rdir)\n",
    "            mkdir(rdir)\n",
    "        end\n",
    "        withmultipleoutput(joinpath(rdir, \"train_log_$ts\")) do\n",
    "            mprintln(repr(\"text/plain\", model))\n",
    "            for k_epoch ∈ 1:no_of_k_epochs\n",
    "                val_losses = zeros(round(Int32, size(y_valid,2) / 32 + 0.5))\n",
    "                val_loss_curve = Array{Float32,1}(undef, no_of_epochs)\n",
    "                train_loss_curve = Array{Float32,1}(undef, no_of_epochs)\n",
    "                for ep ∈ 1:no_of_epochs\n",
    "                    Flux.trainmode!(model, true)\n",
    "                    h = my_train!(model, age_loss, penalty, ps, train_loader, opt; cb = [bcount, mclean, mdeepclean ])\n",
    "                    reset_bcount()\n",
    "                    train_loss_curve[ep] = Statistics.mean(h[:loss])\n",
    "                    mprint(\"\\rEpoch$(k_epoch).$(ep): running against validation set\")\n",
    "                    Flux.testmode!(model, true)\n",
    "                    for (i,b) in enumerate(valid_loader)\n",
    "                        val_losses[i] = age_loss(model, b |> Flux.gpu) # This bit ought to be harmless but isn't needed any more\n",
    "                    end\n",
    "                    mprint(\"\\r                                                     \")\n",
    "                    val_loss_curve[ep] = Statistics.mean(val_losses)\n",
    "                    if val_loss_curve[ep] < best_val_loss\n",
    "                        best_val_loss = val_loss_curve[ep]\n",
    "                        save_model(mpath * \"_val_loss=$(best_val_loss)@epoch_$(ep)\", model, rdir)\n",
    "                    end\n",
    "                    ts = Dates.format(Dates.now(),\"yyyy-mm-dd@HH:MM:SS\")\n",
    "                    if ep % 200 == 0\n",
    "                        mprintln(\"\\r$ts: This is epoch $((k_epoch - 1) * no_of_epochs + ep) and validation loss was $(val_loss_curve[ep]) while training loss was $(train_loss_curve[ep])\")\n",
    "                    end\n",
    "                end\n",
    "                Plots.plot(train_loss_curve)\n",
    "                Plots.plot!(val_loss_curve)\n",
    "                ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "                Plots.savefig(rdir * \"/k_epoch_plot_$(k_epoch)_$(mn)_$(ts)_$(lr).png\")\n",
    "                fw_msg(rdir * \"/k_epoch_plot_$(k_epoch)_$(mn)_$(ts)_$(lr).png\")\n",
    "                save_model(mpath, model, rdir)\n",
    "                append!(global_train_loss_curve, train_loss_curve)\n",
    "                append!(global_val_loss_curve, val_loss_curve)\n",
    "            end\n",
    "            Plots.plot(global_train_loss_curve)\n",
    "            Plots.plot!(global_val_loss_curve)\n",
    "            ts = Dates.format(Dates.now(), \"yyyy-mm-dd-HH-MM-SS\")\n",
    "            Plots.savefig(rdir * \"/global_plot_$(mn)_$(ts)_$(lr).png\")\n",
    "            fw_msg(rdir * \"/global_plot_$(mn)_$(ts)_$(lr).png\")\n",
    "            mprintln(\"\\nPreparing to save accumulated learning data\")\n",
    "            gt_min = minimum(global_train_loss_curve)\n",
    "            gt_end = global_train_loss_curve[end]\n",
    "            gv_min = minimum(global_val_loss_curve)\n",
    "            gv_end = global_val_loss_curve[end]\n",
    "            mprintln(\"Saving accumulated learning data\")\n",
    "            BSON.@save (rdir * \"/global_loss_$(mn)_$(ts)_$(lr)___$(gv_min)_$(gv_end)_$(gt_min)_$(gt_end).bson\") global_train_loss_curve global_val_loss_curve\n",
    "            fw_msg(rdir * \"/global_loss_$(mn)_$(ts)_$(lr)___$(gv_min)_$(gv_end)_$(gt_min)_$(gt_end).bson\")\n",
    "            mprintln(\"Accumulated learning data saved\")\n",
    "        end\n",
    "\n",
    "    catch e\n",
    "        result=\"\\e[38;2;255;0;0mCrashes ($(typeof(e)))\\e[39m \"*repr(MIME(\"text/plain\"), e)\n",
    "        mprintln(\"\\n\",e,\"\\n\")\n",
    "        flush(stdout)\n",
    "        for sf in stacktrace(catch_backtrace())\n",
    "            display(sf)\n",
    "            mprintln()\n",
    "            flush(stdout)\n",
    "        end\n",
    "        if e isa InterruptException\n",
    "            rethrow()\n",
    "        end\n",
    "    finally\n",
    "        mprintln(\"\\r\", \"\", \"\\t\", result)\n",
    "        mprint(\"\\n\\e[38;2;0;0;0;48;2;255;255;0m\")\n",
    "        for i ∈ 0:11\n",
    "            mprint(\" ▁▂▃▄▅▆▇█\" * aecs[1 + i % 2])\n",
    "        end\n",
    "        mprintln(\"\\e[0m\\n\")\n",
    "    end\n",
    "\n",
    "end # end train_and_evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6abcfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include(\"hpiterator.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7543638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runfromfile (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function runfromfile(fn)\n",
    "    # This function takes the name of a file\n",
    "    # It runs ONE training from the file if it finds one suitable\n",
    "    # and deletes the description of that training from the file\n",
    "    # The trainings are described as a line containing:\n",
    "    # <gpu> args=<arguments> kwargs=<keyword arguments>\n",
    "    # where <gpu> is the device number (typically 0, 1 etc)\n",
    "    # args and kwargs are passed to the train_and_evaluate function\n",
    "    lines = open(readlines, fn, \"r\") \n",
    "    # the file is read and closed but a race condition can exist if a processes read the file\n",
    "    # before another one has closed it. This can lead to repeating runs or perhaps dropping some.\n",
    "    # This simply has to be monitored afterwards.\n",
    "    forbiddenkeywords = [:aug, :augmentation, \"aug\", \"augmentation\", ] # things that might show up in the run file but should be dealt with elsewhere\n",
    "\n",
    "    lines_before = Vector{eltype(lines)}()\n",
    "    lines_after = Vector{eltype(lines)}()\n",
    "    cur = nothing\n",
    "    for idx ∈ 1:length(lines) # I know lines doesn't use \"exotic\" indexing\n",
    "        mo = match(r\"^(\\d+)\\D+\", lines[idx])\n",
    "        if !isnothing(mo) # && parse(Int32, mo[1]) % 3 == CUDA.device().handle #Run any job\n",
    "            cur = idx\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    if isnothing(cur)\n",
    "        return false\n",
    "    else\n",
    "        lines_before = lines[1:cur-1]\n",
    "        lines_after = lines[cur+1:end]\n",
    "        open(f->println(f, join(cat(lines_before, lines_after; dims = (1,)), \"\\n\")) , fn, \"w\")\n",
    "        # now the file is written and closed and the race condition over.\n",
    "        line = lines[cur]\n",
    "        mo = match(r\"^(\\d+)\\s+args\\s*=\\s*(.*?)\\s*kwargs\\s*=\\s*(.*)\\s*$\", line)\n",
    "        println(\"mo = $mo\")\n",
    "        if isnothing(mo)\n",
    "            mo = match(r\"^(\\d+)?(\\s+)?(args)?(\\s*)(=)?(\\s*)(.+?\\))?(\\s*)(kwargs)?(\\s*)(=)?(\\s*)(.*)(\\s*)($)?\", line)\n",
    "            if isnothing(mo)\n",
    "                ei = 1\n",
    "            else\n",
    "                println(\"mo = $mo\")\n",
    "                egr = nothing\n",
    "                for gr = 1:13\n",
    "                    if isnothing(mo[gr])\n",
    "                        egr = gr\n",
    "                        println(\"egr = $egr\")\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "                if isnothing(egr) || egr == 1\n",
    "                    ei = 1\n",
    "                else\n",
    "                    ei = mo.offsets[egr - 1] + length(mo[egr - 1])\n",
    "                end\n",
    "            end\n",
    "            markerline = \"\\e[1;38;5;255;255;0m\" * \"─\" ^ (ei - 1) * \"\\e[5m⬏\\e[0m\"\n",
    "            throw(ErrorException(\"Line $idx in $fn does not conform to the syntax.\\n\\n$line\\n$markerline\"))\n",
    "        else\n",
    "            args = eval(Meta.parse(mo[2]))\n",
    "            kwargs = eval(Meta.parse(mo[3]))\n",
    "            for kw in forbiddenkeywords\n",
    "                delete!(kwargs, kw)\n",
    "            end\n",
    "            println(\"Attempting to run train_and_evaluate(args...; kwargs...) with\\n    args   = $args\\n    kwargs = $kwargs\")\n",
    "            train_and_evaluate(args...; kwargs...)\n",
    "        end\n",
    "        return true\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1c7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toc = Inf64\n",
    "while toc > 6000000000000\n",
    "    tic = time_ns()\n",
    "    # below is an attempt at a workaround for some hard to understand world age / CUDA interactions\n",
    "    nextline = readline(\"runs221108\")\n",
    "    mo = match(r\"\\\"([^\\\"]+)\\\"\", nextline)\n",
    "    if ! isnothing(mo)\n",
    "        mfn = mo[1]\n",
    "        load_model(mfn)\n",
    "    end\n",
    "    # End of workaround\n",
    "    runfromfile(\"runs221108\")\n",
    "    toc = time_ns() - tic\n",
    "    println(\"toc = $toc ($(round(Int32, toc / 10 ^ 9)) s)\\n\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffc4fef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLUtils.DataLoader{NamedTuple{(:d₁, :d₂, :d₃, :l), Tuple{Array{Float32, 4}, Array{Float32, 4}, Array{Float32, 4}, Matrix{Float32}}}, Random._GLOBAL_RNG, Val{nothing}}((d₁ = Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], d₂ = Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], d₃ = Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0]\n",
       "\n",
       "Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], l = Float32[62.0 70.0 … 61.0 69.0; 0.0 1.0 … 0.0 1.0]), 32, false, true, true, false, Val{nothing}(), Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = Flux.DataLoader((d₁ = train_loader.data[:d₁], d₂ = train_loader.data[:d₂], d₃ = train_loader.data[:d₃], l = train_loader.data[:l]) , batchsize = 32, shuffle = true);\n",
    "train_loader = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f571d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has positional arguments\n",
      "Looks like a collection\n",
      "Is a set of channels\n",
      "Channel model called with:\n",
      "args:\n",
      "  1: 2\n",
      "  2: 4\n",
      "  3: 6\n",
      "\n",
      "kwargs:\n",
      "Building model with channels 2, 4 and 6\n",
      "Received request to open /home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/train_log_2022-11-09-10-04-51\n",
      "File opened, returning filehandle\n",
      "Entering \"with-multiple-output\"-context.\n",
      "Chain(\n",
      "  Parallel(\n",
      "    var\"#99#115\"(),\n",
      "    Chain(\n",
      "      var\"#89#104\"(),\n",
      "      Conv((3, 3), 1 => 4, σ, pad=1),   # 40 parameters\n",
      "      Conv((3, 3), 4 => 4, pad=1, stride=2, bias=false),  # 144 parameters\n",
      "      BatchNorm(4, σ),                  # 8 parameters, plus 8\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 4 => 8, σ, pad=1),   # 296 parameters\n",
      "      Conv((3, 3), 8 => 8, pad=1, stride=2, bias=false),  # 576 parameters\n",
      "      BatchNorm(8, σ),                  # 16 parameters, plus 16\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 8 => 16, σ, pad=1),  # 1_168 parameters\n",
      "      Conv((3, 3), 16 => 16, pad=1, stride=2, bias=false),  # 2_304 parameters\n",
      "      BatchNorm(16, σ),                 # 32 parameters, plus 32\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 16 => 32, σ, pad=1),  # 4_640 parameters\n",
      "      Conv((3, 3), 32 => 32, pad=1, stride=2, bias=false),  # 9_216 parameters\n",
      "      BatchNorm(32, σ),                 # 64 parameters, plus 64\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 32 => 64, σ, pad=1),  # 18_496 parameters\n",
      "      Conv((3, 3), 64 => 64, pad=1, stride=2, bias=false),  # 36_864 parameters\n",
      "      BatchNorm(64, σ),                 # 128 parameters, plus 128\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 64 => 128, σ, pad=1),  # 73_856 parameters\n",
      "      Conv((3, 3), 128 => 128, pad=1, stride=2, bias=false),  # 147_456 parameters\n",
      "      BatchNorm(128, σ),                # 256 parameters, plus 256\n",
      "      Dropout(0.2),\n",
      "      Conv((4, 4), 128 => 256, σ),      # 524_544 parameters\n",
      "      var\"#90#105\"(),\n",
      "    ),\n",
      "    Chain(\n",
      "      var\"#92#108\"(),\n",
      "      Conv((3, 3), 1 => 4, σ, pad=(1, 0)),  # 40 parameters\n",
      "      Conv((3, 3), 4 => 4, pad=1, stride=2, bias=false),  # 144 parameters\n",
      "      BatchNorm(4, σ),                  # 8 parameters, plus 8\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 4 => 8, σ, pad=(1, 0)),  # 296 parameters\n",
      "      Conv((3, 3), 8 => 8, pad=1, stride=2, bias=false),  # 576 parameters\n",
      "      BatchNorm(8, σ),                  # 16 parameters, plus 16\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 8 => 16, σ, pad=(1, 0)),  # 1_168 parameters\n",
      "      Conv((3, 3), 16 => 16, pad=1, stride=2, bias=false),  # 2_304 parameters\n",
      "      BatchNorm(16, σ),                 # 32 parameters, plus 32\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 16 => 32, σ, pad=(1, 0)),  # 4_640 parameters\n",
      "      Conv((3, 3), 32 => 32, pad=1, stride=2, bias=false),  # 9_216 parameters\n",
      "      BatchNorm(32, σ),                 # 64 parameters, plus 64\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 32 => 64, σ, pad=(1, 0)),  # 18_496 parameters\n",
      "      Conv((3, 3), 64 => 64, pad=1, stride=2, bias=false),  # 36_864 parameters\n",
      "      BatchNorm(64, σ),                 # 128 parameters, plus 128\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 64 => 128, σ),       # 73_856 parameters\n",
      "      Conv((3, 3), 128 => 128, pad=1, stride=2, bias=false),  # 147_456 parameters\n",
      "      BatchNorm(128, σ),                # 256 parameters, plus 256\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 128 => 256, σ),      # 295_168 parameters\n",
      "      var\"#93#109\"(),\n",
      "    ),\n",
      "    Chain(\n",
      "      var\"#96#112\"(),\n",
      "      Conv((3, 3), 1 => 4, σ, pad=(1, 0)),  # 40 parameters\n",
      "      Conv((3, 3), 4 => 4, pad=1, stride=2, bias=false),  # 144 parameters\n",
      "      BatchNorm(4, σ),                  # 8 parameters, plus 8\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 4 => 8, σ, pad=(1, 0)),  # 296 parameters\n",
      "      Conv((3, 3), 8 => 8, pad=1, stride=2, bias=false),  # 576 parameters\n",
      "      BatchNorm(8, σ),                  # 16 parameters, plus 16\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 8 => 16, σ, pad=(1, 0)),  # 1_168 parameters\n",
      "      Conv((3, 3), 16 => 16, pad=1, stride=2, bias=false),  # 2_304 parameters\n",
      "      BatchNorm(16, σ),                 # 32 parameters, plus 32\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 16 => 32, σ, pad=(1, 0)),  # 4_640 parameters\n",
      "      Conv((3, 3), 32 => 32, pad=1, stride=2, bias=false),  # 9_216 parameters\n",
      "      BatchNorm(32, σ),                 # 64 parameters, plus 64\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 32 => 64, σ, pad=(1, 0)),  # 18_496 parameters\n",
      "      Conv((3, 3), 64 => 64, pad=1, stride=2, bias=false),  # 36_864 parameters\n",
      "      BatchNorm(64, σ),                 # 128 parameters, plus 128\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 64 => 128, σ),       # 73_856 parameters\n",
      "      Conv((3, 3), 128 => 128, pad=1, stride=2, bias=false),  # 147_456 parameters\n",
      "      BatchNorm(128, σ),                # 256 parameters, plus 256\n",
      "      Dropout(0.2),\n",
      "      Conv((3, 3), 128 => 256, σ),      # 295_168 parameters\n",
      "      var\"#97#113\"(),\n",
      "    ),\n",
      "  ),\n",
      "  Dense(768 => 10, σ),                  # 7_690 parameters\n",
      "  Dense(10 => 1),                       # 11 parameters\n",
      ")         # Total: 100 trainable arrays, 2_009_261 parameters,\n",
      "          # plus 36 non-trainable, 1_512 parameters, summarysize 40.289 KiB.\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=28.801716@epoch_13_2022-11-09-13-03-00.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=25.970758@epoch_14_2022-11-09-13-17-15.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=22.155756@epoch_18_2022-11-09-14-13-09.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=21.993692@epoch_26_2022-11-09-16-05-47.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=21.09831@epoch_30_2022-11-09-17-01-51.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=20.5358@epoch_32_2022-11-09-17-29-46.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=20.20892@epoch_40_2022-11-09-19-21-52.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=19.778265@epoch_44_2022-11-09-20-17-39.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=19.773228@epoch_47_2022-11-09-20-59-30.mdl.bson'\n",
      "File written to path:                                                                \n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_val_loss=19.284435@epoch_71_2022-11-10-02-37-07.mdl.bson'\n",
      "File written to path:                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/k_epoch_plot_1_model_channel_toggle.jl_channels=2.4.6_2022-11-10-09-25-27_0.003.png'\n",
      "File written to path:\n",
      "  '/home/johjo50/3Dto2D/v1/results/results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/model_model_channel_toggle.jl_2022-11-10-09-25-43.mdl.bson'\n",
      "742                                                                                  "
     ]
    }
   ],
   "source": [
    "let args   = (\"models/model_channel_toggle.jl\", [2, 4, 6], (), Dict{Any, Any}()), kwargs = Dict(:identifier => \"model_channel_toggle.jl_channels=2.4.6\")\n",
    "    train_and_evaluate(args...; kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66452db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_model_channel_toggle.jl_channels=2.4.6_2022-11-09-10-04-51_0.003/k_epoch_plot_1_model_channel_toggle.jl_channels=2.4.6_2022-11-10-09-25-27_0.003.png"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia (36t) 1.6.4",
   "language": "julia",
   "name": "julia-(36t)-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
